---
{"dg-publish":true,"permalink":"/paper-review/controllable-diffusion-models/"}
---

[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Fang_Data_Augmentation_for_Object_Detection_via_Controllable_Diffusion_Models_WACV_2024_paper.pdf)
[Code](https://github.com/FANGAreNotGnu/ControlAug)
## abstract

Objbect Detection 작업에서 Data Augmentation을 수행하기 위해 **Controllable Diffusion Models**을 사용한다.
특히, 객체 탐지는 **expensive bounding box annotations**이 필요한데, 이 주석 작업은 시간과 비용이 많이 든다. 
이를 해결하기 위해 이 논문은 **diffusion model**과 **CLIP**을 활용하여 **synthetic data**를 생성하고, 그 데이터를 통해 성능을 향상시키는 방법을 제안한다.

1. **확산 모델을 이용한 합성 이미지 생성**
   - 확산 모델을 사용해 이미지 데이터를 증강하며, CLIP을 통해 **visual priors**를 제어하여 **카테고리에 맞는 데이터**를 생성한다.
   - 이를 통해 기존의 데이터 증강 방법보다 더 정교하게 **특정 카테고리**에 맞는 이미지를 생성할 수 있다.

2. **포스트 필터링(Post-filtering)
   - 생성된 합성 데이터 중 **카테고리-보정된 CLIP 점수**를 사용하여 품질이 낮은 이미지를 필터링한다. 
   - 이를 통해 **높은 품질의 데이터**만 학습에 사용되도록 보장한다.

3. **Few-shot 설정에서 성능 향상**
   - 논문에서는 **MSCOCO**, **PASCAL VOC** 데이터셋을 활용한 실험에서 성능 향상을 확인했다. 특히, 적은 양의 데이터만으로도 효과적인 성능 향상을 보여주었으며, few-shot 설정에서 성능 개선을 입증했다.
   - COCO의 5/10/30-shot 설정에서는 각각 **+18.0%**, **+15.6%**, **+15.9%** 의 mAP 성능 향상을 보였다.
   - PASCAL VOC 전체 데이터셋에서는 **+2.9%**, 기타 다운스트림 데이터셋에서는 평균 **+12.4%** 의 성능 향상을 보였다.

**객체 탐지(Object Detection)** 모델이 최첨단 성능을 발휘하기 위해서는 **대규모의 다양하고 주석된 데이터셋**이 필요하다. 객체 탐지는 단순히 이미지 분류를 넘어서 **정확한 바운딩 박스(bounding box)** 주석이 필요하다.

## Intro

![Figure 1.](https://i.imgur.com/HWnOvce.png) Figure 1.

![](https://i.imgur.com/uKGGoWf.png)

객체 탐지를 위한 데이터 증강 기법을 제안한다. 객체 탐지(Object Detection)는 이미지 분류보다 더 복잡한 주석 작업이 필요하며, 정확한 바운딩 박스(bounding box) 정보를 추가로 포함해야 한다. 새로운 데이터를 주석하는 대신, 데이터 증강(data augmentation)을 활용해 기존 데이터를 변형하여 더 많은 학습 데이터를 생성하는 방법이 주로 사용된다. 전통적인 데이터 증강은 회전, 크기 조정, 이미지 뒤집기 등의 방법을 포함하지만, 최근에는 생성 모델을 활용한 데이터 증강이 주목받고 있다.

### ideas

1. **diffusion models**
	생성 기반 데이터 증강은 비생성 방식으로는 얻을 수 없는 다양성과 현실성, 새로운 시각적 특징을 학습 데이터에 추가할 수 있다는 장점이 있다. 하지만 생성된 이미지에서 객체 탐지를 위해 정확한 바운딩 박스 주석을 얻는 것은 어려운 과제이다. 이를 해결하기 위해, 저자들은 확산 모델(diffusion models)을 사용하여 바운딩 박스를 지정한 후, 그 내부에 객체를 생성하는 방법을 제안한다. 또한 텍스트 기반 이미지 생성과 시각적 사전 정보를 결합해 스타일, 조명, 객체를 다르게 생성하면서도 고품질의 바운딩 박스를 유지하는 방법도 탐구하였다.

2. **CLIP 기반 필터링**
	보정된 CLIP 점수를 사용하여 생성된 이미지의 품질을 자동으로 제어하며, 페인트 기법을 결합해 성능을 더 개선하는 방법을 제안한다. 이 방법은 MSCOCO, PASCAL VOC 등의 데이터셋에서 실험을 통해 평가되었으며, 소량의 데이터로도 성능을 크게 개선할 수 있음을 보였다. YOLOX 탐지기의 성능은 소량의 COCO 데이터셋에서 최대 18.0% 개선되었고, 전체 PASCAL VOC 데이터셋에서는 2.9% 향상되었다.

## Method

![](https://i.imgur.com/Diy6Nql.png)

1. Visual Prior Generator
2. Prompt Constructor
3. Controllable Diffusion Model
4. Post Filter with Category-Calibrated CLIP Rank
### 2.1. Prior Extractor 
	(비주얼 프라이어 추출기)
- **Visual Prior Generator**는 훈련에 사용될 이미지-주석 쌍에서 M개의 이미지를 샘플링하고, 일반적인 데이터 변환을 적용하여 "비주얼 프라이어-주석 쌍"을 생성한다. 기본적으로 HED 에지 검출기(HED edge detector)를 사용하며, 다른 비주얼 프라이어 추출기도 논의된다(예: Canny 에지 검출기, 세그멘테이션 마스크).

### 2.2. Prompt Construction 
	(프롬프트 생성)
- 주석 정보에 따라 프롬프트를 생성하며, 기본 전략은 주석에 있는 모든 카테고리 라벨을 하나의 문장으로 결합하는 것이다. 여러 가지 다른 전략도 실험하였으나, 기본 전략이 가장 효과적임이 밝혀졌다.

### 2.3. Controllable Diffusion Model 
	(제어 가능한 확산 모델)
- 확산 모델을 사용하여 주석된 이미지-프롬프트 쌍으로부터 합성 이미지를 생성한다. 미리 훈련된 모델의 일부 파라미터는 고정되고, 다른 부분은 업데이트된다. 이 과정에서 생성된 이미지는 주석과 일치하는 구조를 가지며, 결과적으로 고품질의 바운딩 박스가 포함된 합성 이미지-주석 쌍이 생성된다.

### 2.4. Post Filter with Category-Calibrated CLIP Rank 
	카테고리 보정된 CLIP 점수를 사용한 후처리 필터
- 생성된 이미지 내에서 바운딩 박스 안의 객체가 프롬프트와 일치하는지 확인하기 위해 CLIP 점수를 계산한다. 그런 다음 각 주석에 대해 유사도 점수를 수집하고, 이를 기반으로 데이터의 품질을 평가하여 상위 품질의 합성 데이터를 필터링한다.

![](https://i.imgur.com/53VEti3.png)Table 1.
## Main Results
### 3.1. 실험 설정
기본 실험 설정
- **합성 데이터 생성 필터링 비율**(γ): 30%
- **증강 비율**(α): 1
- **합성 이미지 크기**: 512x512
- **샘플링 방식**: DDIM (50 스텝)
- **가이던스 스케일**: 9.0
- **비주얼 프라이어**: HED 엣지 디텍터

탐지기 별로 사용된 최적화 방법
- **YOLOX-S**: SGD 옵티마이저, 배치 크기 64, 학습률 1e-2, 모멘텀 0.9, weight decay 5e-4, 사전 훈련은 200 에포크 진행.
- **DINO-SwinL**: AdamW 옵티마이저, 배치 크기 16, 학습률 1e-4, weight decay 1e-4, 사전 훈련은 36 에포크.

평가
**COCO-standard mAP**와 **VOC-standard AP50**으로 진행되었으며, 일부 실험에서는 **AP75**, **mAP-small**, **mAP-medium**, **mAP-large**도 보충 자료로 포함되었다.

### 3.2. Few Shot 실험
**Few-Shot Object Detection (FSOD)** 설정에서 제안된 데이터 증강 파이프라인을 COCO 데이터셋에서 평가했다. FSOD는 소량의 라벨이 있는 데이터로 객체를 탐지하는 어려운 문제를 다루며, 새로운 객체 클래스에 대한 소수의 예시만으로 일반화해야 하는 시나리오를 다룬다.

COCO 데이터셋의 80개 객체 카테고리 중 60개는 베이스 카테고리로, 나머지 20개는 새로운 카테고리로 나누어 베이스 카테고리 데이터로 사전 훈련을 진행하고, 새로운 카테고리에서 K-shot (5, 10, 30) 데이터를 샘플링하여 실험을 진행했다.

**Table 1**에서 볼 수 있듯이, YOLOX-S와 DINO-SwinL 탐지기를 사용하여 다양한 shot에서 제안된 방법과 기존 방법을 비교했다. 특히 SDInpaint 및 Paint-by-Example (PbE) 방법과 비교했을 때, shot 수가 증가할수록 인페인팅 방법의 개선 효과가 크게 줄어들었다는 점을 발견했다. 이는 적은 데이터에서는 바운딩 박스가 약간 느슨하더라도 합성 객체가 모델의 성능을 향상시킬 수 있지만, 실제 데이터가 충분히 많아지면 정확한 바운딩 박스가 중요한 요소가 된다는 것을 의미한다.

이 논문의 **Main Results** 섹션의 추가 내용에서는 제안된 데이터 증강 기법이 다양한 설정에서 얼마나 효과적인지 더 구체적으로 다루고 있다.

### 3.3. PASCAL VOC 데이터셋
PASCAL VOC 데이터셋 전체에 대해 성능을 평가한 결과, 충분한 주석이 있는 경우에도 탐지기의 성능을 크게 향상시킬 수 있음을 보여주었다. **YOLOX-S** 탐지기를 사용하여 **VOC0712 trainval** 데이터를 300 에포크 동안 학습하고 **VOC07 test** 세트에서 평가한 결과, 제안된 증강 기법을 통해 mAP +1.2, mAP50 +0.8, mAP75 +1.4의 성능 향상이 있었다.
![](https://i.imgur.com/fby2Ik7.png)
### 3.4. 
동일한 탐지기 설정을 사용하여 몇 가지 다운스트림 객체 탐지 데이터셋에서도 성능을 평가하였다. 이 실험은 제안된 방법이 다양한 도메인에 대해 일반화될 수 있음을 입증하기 위한 목적으로 수행되었다. **Table 2**에서 확인할 수 있듯이, 여러 데이터셋에서 성능이 크게 향상되었으며, 평균적으로 mAP는 33.8에서 38.0으로, AP50은 58.2에서 61.4로 개선되었다.

##  Discussion and Analysis

**데이터 증강 파이프라인**의 성능을 평가
1. **카테고리 보정 CLIP 필터링**의 중요성
2. **적절한 증강 비율**
3. **프롬프트 구성 방법**
4. **다른 증강 기법과의 호환성**
5. **충분한 합성 데이터가 있으면 실제 데이터가 여전히 필요한가?**
6. **인페인팅 기법과의 결합 가능성**
7. **다른 유형의 비주얼 프라이어의 성능**

![](https://i.imgur.com/082HfUL.png)
### 4.1. 
Table 3에서 보여지듯이, 카테고리 보정된 CLIP 필터링을 적용하면 성능이 전반적으로 비필터링 데이터보다 더 향상된다. 특히, 필터링 비율이 30%일 때 성능이 크게 향상되었으며, 5-shot에서는 +13.5% mAP, 10-shot에서는 +5.7%, 30-shot에서는 +6.0%의 성능 향상이 있었다. 그러나 필터링 비율이 너무 낮아지면 성능이 감소하는 현상을 관찰할 수 있었으며, 이는 직관과는 상반되는 결과이다. 필터링 비율이 낮을수록 합성 데이터의 품질이 더 좋아야 할 것 같지만, 너무 낮은 비율에서는 성능이 오히려 떨어지는 경향을 보였다.

이러한 실험 결과들은 필터링 비율이 적절하게 설정되어야 성능 향상이 극대화된다는 것을 보여주고 있으며, 제안된 데이터 증강 방법이 기존 방법보다 상당히 효과적임을 확인할 수 있다.


![](https://i.imgur.com/ifsUFAi.png)
### 4.2. 
고품질의 합성 데이터를 생성한 후, 얼마만큼의 합성 데이터를 사용할 것인지, 즉 증강 비율(α)에 대한 질문이 생긴다. **Figure 5**에서는 다양한 증강 비율에 따른 성능을 보여준다. 실험 결과에 따르면, **1 ≤ α ≤ 4** 범위에서 최적의 성능을 달성할 수 있음을 알 수 있다. 이 연구의 다른 부분에서는 성능과 효율성을 균형 있게 맞추기 위해 **α = 1**을 기본으로 사용하였다.

일반적으로 데이터 양이 많아지면 성능이 향상된다고 생각할 수 있지만, 증강 비율이 지나치게 높아지면 성능이 오히려 떨어진다는 것을 발견했다. 이는 4.1절에서 언급된 도메인 이동 문제와 유사하다. 합성 데이터와 실제 데이터 간의 도메인 차이, 주로 이미지 스타일에서의 차이로 인해, 과도한 합성 데이터를 추가하면 전체 데이터 분포가 변하고 객체 탐지기의 성능을 혼란스럽게 만들 수 있다.

![](https://i.imgur.com/OX5Dsnk.png)

### 4.3. 
이전의 확산 기반 데이터 증강 연구는 주로 하나의 카테고리만을 포함한 프롬프트를 사용하였다. 예를 들어, 고정된 프롬프트 "a photo of a single 〈카테고리 이름〉"을 사용하고, 6개의 고정된 패턴을 혼합하여 사용하며, 단순히 카테고리 이름만을 사용한다. 이 연구에서는 여러 카테고리 이름을 포함한 프롬프트가 필요하기 때문에, Table 4에서 설명된 대로 다양한 프롬프트 구성 방법을 탐구하였다.

프롬프트 구성 방법으로는 다음과 같은 전략이 포함된다:
- **concatenat**: 모든 바운딩 박스의 카테고리 이름을 쉼표로 구분하여 단순히 연결함.
- **and**: 쉼표 대신 "and"로 구분.
- **shuffledset**: 중복된 카테고리 이름을 제거한 뒤 무작위 순서로 나열.
- **shuffledsetand**: 무작위 순서로 나열하고 "and"로 구분.
- **img**: 연결된 문장 앞에 "An image of"를 추가.
- **mix**: 위 전략들을 무작위로 선택해 혼합.

![](https://i.imgur.com/PBq7zs0.png)
**Figure 6**에서 볼 수 있듯이, 단순히 카테고리 이름을 쉼표나 "and"로 구분하여 연결하는 방식이 일관되게 좋은 성능을 보였다. 반면, 더 복잡한 전략을 추가하면 강건성이 감소하는 경향을 보였다.

### 4.4. 
다른 데이터 증강 기법과 결합했을 때 성능을 비교하였다. 구체적으로는 **YOLOX-S**에서 모자이크 증강 없이/있이 실험을 진행하고, **DINO-SwinL**에서는 무작위 크기 조정 없이/있이 실험을 진행하였다. **Figure 8**에 나타난 결과에 따르면, 추가적인 데이터 증강이 있어도 제안된 방법은 일관되게 좋은 성능을 유지하는 것으로 나타났다.

### 4.5. 
실제 데이터와 합성 데이터를 혼합하여 실험한 결과를 **Table 7**에 제시하였다. **VOC 데이터셋**에서 합성 데이터와 0%, 1%, 10%, 50%, 100%의 실제 데이터를 섞어 성능을 비교하였다. mAP, AP50, AP75, 그리고 mAP-small/medium/large 지표를 사용한 결과, 실제 데이터가 증가함에 따라 성능이 크게 향상되는 것을 확인할 수 있었다.

### 4.6. 
인페인팅(Inpainting) 기법은 대규모 이미지-캡션 쌍으로 사전 학습되었기 때문에 데이터에 더 다양한 객체를 추가할 수 있다. 그러나 인페인팅 알고리즘이 바운딩 박스를 정확히 채우도록 강제할 수 없기 때문에, 박스가 느슨해져 훈련 데이터에 노이즈가 발생하는 문제가 있다. Section 3.2에서 COCO 데이터셋에서 소량의 학습 데이터로 인페인팅 기법보다 더 우수한 성능을 보였다는 결과를 제시하였다. 여기서는 인페인팅 기법을 제안된 파이프라인에 통합하여 성능을 더욱 향상시킬 가능성을 탐구하였다.

**COCO 데이터셋**에서 10-shot 설정으로 인페인팅 기법 **PbE**를 통합한 실험 결과는 **Table 6**에 나와 있다. 주요 결과는 다음과 같다:
1. **PbE 단독**: PbE만 사용했을 때는 탐지기 성능이 개선되지 않았다.
2. **PbE + 제안 방법**: 제안된 방법으로 생성된 합성 이미지를 추가하면 PbE 성능이 향상되었고, **AP50**에서 +1.0 향상을 보였으나 **mAP**에서는 -0.1 감소했다.
3. **PbE + 30%PF**: 카테고리 보정 CLIP 점수로 30%의 포스트 필터링을 적용하면 성능이 크게 향상되었다.
4. **PbE + 제안 방법 + 30%PF**: 제안된 방법과 포스트 필터링을 추가하면 소형/중형 객체 탐지 성능이 더 향상되었다.
5. **PbE(적게) + 제안 방법(많게) + 30%PF**: PbE로 생성된 합성 데이터의 양을 줄이고 제안된 방법으로 생성된 데이터를 늘리면 증강 성능이 가장 크게 향상되었다.

### 4.7. 
다양한 비주얼 프라이어를 사용한 결과를 비교하였다. **HED 엣지**, **Canny 엣지**, **Uniformer로 생성된 세그멘테이션 마스크**, **Scribble**을 사용하여 COCO에서 소량의 학습 데이터로 실험하였다. 결과는 **Table 8**에 나와 있다. **HED 엣지**와 비교했을 때, **Canny 엣지**는 노이즈에 더 취약하여, 일부 실험에서 더 높은 mAP를 기록했지만, 합성 데이터의 품질은 전반적으로 낮고 성능도 떨어졌다. **마스크**와 **Scribble**을 사용한 비주얼 프라이어는 더 다양한 객체 외관을 생성하지만, 그만큼 더 많은 합성 특징을 포함하여 성능이 저하되었다. 참고로, **Uniformer**는 세그멘테이션 데이터셋에서 학습된 모델이다.

## Conclusion
제어 가능한 확산 모델과 CLIP을 기반으로 한 새로운 데이터 증강 기법을 소개하였다. 이 기법은 객체 탐지 작업을 위해 설계되었으며, COCO 데이터셋의 소량 학습 설정, 전체 PASCAL VOC 데이터셋, 그리고 다양한 다운스트림 객체 탐지 데이터셋에서 평가되었다. 실험 결과, 제안된 방법이 객체 탐지기의 성능을 크게 향상시키는 것으로 나타났다.

또한, 제안된 방법의 다양한 질문과 분석을 통해 인페인팅 기법을 통합하면 그 효과가 더욱 증가함을 확인하였다. 다른 데이터 증강 기법과의 시너지도 관찰되었으며, 제안된 방법은 다른 증강 기법과 결합하여 성능을 더욱 향상시킬 수 있음을 보여주었다.