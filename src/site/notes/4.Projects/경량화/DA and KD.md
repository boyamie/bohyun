---
{"dg-publish":true,"permalink":"/4-projects//da-and-kd/"}
---

[A Survey on Knowledge Distillation of Large Language Models](https://arxiv.org/html/2402.13116v1)
LLM 시대에 데이터 증강(DA)  Wang et al. ([2022년](https://arxiv.org/html/2402.13116v1#bib.bib40)); Ye et al. ([2022](https://arxiv.org/html/2402.13116v1#bib.bib41))는 지식 증류 과정에 필수적인 중요한 패러다임으로 등장합니다.  Gangal et al.의 의역과 같은 전통적인 DA 기술과는 달리([2022](https://arxiv.org/html/2402.13116v1#bib.bib42)) 또는 역번역  Longpre et al. ([2019](https://arxiv.org/html/2402.13116v1#bib.bib43)) , 주로 다소 기계적인 방식으로 훈련 데이터 세트를 확장하는 것을 목표로 합니다. LLM 맥락 내의 DA는 특정 도메인과 기술에 맞게 조정된 새롭고 맥락이 풍부한 훈련 데이터를 생성하는 데 중점을 둡니다. 이 혁신은 다양한 분야의 인간 전문가의 미묘한 이해와 인지 능력을 면밀히 모방하는 일관되고 다양하며 복잡한 데이터 샘플을 생성하는 LLM의 고유한 역량에 의해 주도됩니다.

LLM에서 DA와 KD의 관계는 공생적이고 기초적입니다. 일련의 시드 지식을 활용하여 KD는 DA를 사용하여 LLM이 특정 기술이나 도메인 전문 지식을 캡슐화하는 명시적 데이터를 생성하도록 촉구합니다.  Chaudhary([2023](https://arxiv.org/html/2402.13116v1#bib.bib21)); West et al. ([2022](https://arxiv.org/html/2402.13116v1#bib.bib44)) . 이 방법은 독점 모델과 오픈 소스 모델 간의 지식과 역량 격차를 메우는 강력한 메커니즘으로 돋보입니다. DA를 통해 LLM은 단순히 볼륨이 더 클 뿐만 아니라 다양성과 특이성이 풍부한 타겟팅된 고품질 데이터 세트를 만들도록 유도됩니다. 이 접근 방식은 증류 프로세스를 보다 효과적으로 수행하여 증류된 모델이 교사 모델의 출력 동작을 복제할 뿐만 아니라 깊이 자리 잡은 이해와 인지 전략을 구현하도록 보장합니다.

LLM 시대에 KD를 달성하기 위한 DA의 중요성과 필요성은 과장할 수 없습니다. DA는 힘의 증폭기 역할을 하여, 증류된 모델이 그렇지 않으면 기하급수적으로 더 큰 데이터 세트와 계산 리소스가 필요할 역량을 획득하고 개선할 수 있도록 합니다. DA는 양적 확장보다는 학습의 질적 측면에 초점을 맞추어 지식의 보다 미묘하고 효과적인 전달을 용이하게 합니다. KD 프로세스 내에서 DA를 전략적으로 사용하는 것은 LLM의 힘을 활용하기 위한 보다 효율적이고 지속 가능하며 접근 가능한 접근 방식으로의 중요한 전환을 강조합니다. 오픈소스 모델이 독점적인 대응 모델의 맥락적 적응성, 윤리적 일치, 심층적인 의미적 통찰력을 근사할 수 있는 능력을 제공하여 고급 AI 역량에 대한 접근성을 민주화하고 더 광범위한 애플리케이션과 사용자에 걸쳐 혁신을 촉진합니다.