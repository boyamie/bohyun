---
{"dg-publish":true,"permalink":"/4-projects/semantic-seg/24-11-19/"}
---

| **모델**                               | **강점**                          | **추천 이유**                  |
| ------------------------------------ | ------------------------------- | -------------------------- |
| **Mask2Former**                      | 복잡한 세그멘테이션 작업에서 높은 정확도          | 뼈의 구조와 경계를 정밀하게 구분.        |
| **Swin Transformer + UperNet**       | 고해상도 데이터와 복잡한 클래스 처리에 적합        | 뼈의 세부 구조를 고정밀도로 분리 가능.     |
| **Pyramid Vision Transformer (PVT)** | 메모리 효율적이며 고성능 Transformer 구조 제공 | 고해상도 뼈 데이터 작업에서 효율적.       |
| **MobileViT**                        | 경량화된 모델, 제한된 자원 환경에서 적합         | 리소스 제약이 있는 환경에서 사용.        |
| **EfficientNet**                     | 효율성과 정확성 간의 균형 제공               | 고성능이 필요하지 않은 경량 세그멘테이션 작업. |
## Mask2Former
![](https://i.imgur.com/kSHMMyN.png)

31개 매개변수 확장

매개변수

- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.backbone_config)**backbone_config** ( `PretrainedConfig`또는 `dict`, _선택 사항_ , 기본값은 `SwinConfig()`) — 백본 모델의 구성입니다. 설정하지 않으면 에 해당하는 구성이 `swin-base-patch4-window12-384`사용됩니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.backbone)**backbone** ( `str`, _선택 사항_`backbone_config` ) — is 일 때 사용할 백본의 이름입니다 `None`. `use_pretrained_backbone`is 인 경우 `True`timm 또는 transformers 라이브러리에서 해당 사전 학습된 가중치를 로드합니다. `use_pretrained_backbone` is 인 경우 `False`백본의 구성을 로드하고 이를 사용하여 랜덤 가중치로 백본을 초기화합니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.use_pretrained_backbone)**use_pretrained_backbone** ( `bool`, _선택 사항_ , `False`) — 백본에 사전 훈련된 가중치를 사용할지 여부.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.use_timm_backbone)**use_timm_backbone** ( `bool`, _선택 사항_ , ) — timm 라이브러리에서 `False`로드할지 여부 . 이면 백본은 transformers 라이브러리에서 로드됩니다.`backbone``False`
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.backbone_kwargs)**backbone_kwargs** ( `dict`, _선택 사항_ ) — 체크포인트에서 로드할 때 AutoBackbone에 전달되는 키워드 인수 예 : . 설정된 `{'out_indices': (0, 1, 2, 3)}`경우 지정할 수 없습니다 .`backbone_config`
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.feature_size)**feature_size** ( `int`, _선택 사항_ , 기본값은 256) — 결과 피처 맵의 피처(채널).
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.mask_feature_size)**mask_feature_size** ( `int`, _선택 사항_ , 기본값은 256) — 마스크의 피처 크기. 이 값은 피처 피라미드 네트워크 피처의 크기를 지정하는 데에도 사용됩니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.hidden_dim)**hidden_dim** ( `int`, _선택 사항_ , 기본값은 256) — 인코더 레이어의 차원.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.encoder_feedforward_dim)**인코더_피드포워드_dim** ( `int`, _선택 사항_ , 기본값은 1024) — 픽셀 디코더의 일부로 사용되는 변형 가능한 디트롤 인코더의 피드포워드 네트워크 차원입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.encoder_layers)**인코더_레이어** ( `int`, _선택 사항_ , 기본값 6) — 픽셀 디코더의 일부로 사용되는 변형 가능한 detr 인코더의 레이어 수입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.decoder_layers)**decoder_layers** ( `int`, _선택 사항_ , 기본값은 10) — Transformer 디코더의 레이어 수.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.num_attention_heads)**num_attention_heads** ( `int`, _선택 사항_ , 기본값은 8) — 각 어텐션 레이어의 어텐션 헤드 수.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.dropout)**dropout** ( `float`, _선택 사항_ , 기본값은 0.1) — 임베딩의 모든 완전 연결 계층에 대한 드롭아웃 확률, 인코더.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.dim_feedforward)**dim_feedforward** ( `int`, _선택 사항_ , 기본값은 2048) — 변압기 디코더의 피드포워드 네트워크의 피처 차원.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.pre_norm)**pre_norm** ( `bool`, _선택 사항_ , 기본값 `False`) — 변압기 디코더에 pre-LayerNorm을 사용할지 여부입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.enforce_input_projection)**enforcement_input_projection** ( `bool`, _선택 사항_ , 기본값 `False`) — Transformer 디코더에서 입력 채널과 숨겨진 dim이 동일하더라도 입력 투영 1x1 합성곱을 추가할지 여부입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.common_stride)**common_stride** ( `int`, _선택 사항_ , 기본값은 4) — 픽셀 디코더의 일부로 사용되는 FPN 레벨 수를 결정하는 데 사용되는 매개변수입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.ignore_value)**ignore_value** ( `int`, _선택 사항_ , 기본값은 255) — 학습 중 무시할 카테고리 ID입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.num_queries)**num_queries** ( `int`, _선택 사항_ , 기본값은 100) — 디코더에 대한 쿼리 수.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.no_object_weight)**no_object_weight** ( `int`, _선택 사항_ , 기본값은 0.1) — null(객체 없음) 클래스에 적용할 가중치입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.class_weight)**class_weight** ( `int`, _선택 사항_ , 기본값은 2.0) — 교차 엔트로피 손실에 대한 가중치입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.mask_weight)**mask_weight** ( `int`, _선택 사항_ , 기본값은 5.0) — 마스크 손실에 대한 가중치입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.dice_weight)**dice_weight** ( `int`, _선택 사항_ , 기본값은 5.0) — 주사위 손실의 가중치입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.train_num_points)**train_num_points** ( `str`또는 _선택 사항_`function` , 기본값은 12544) — 손실 계산 중 샘플링에 사용되는 포인트 수.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.oversample_ratio)**oversample_ratio** ( `float`, _선택 사항_ , 기본값은 3.0) — 샘플링된 포인트 수를 계산하는 데 사용되는 오버샘플링 매개변수
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.importance_sample_ratio)**importance_sample_ratio** ( `float`, _선택 사항_ , 기본값은 0.75) — 중요도 샘플링을 통해 샘플링된 포인트의 비율.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.init_std)**init_std** ( `float`, _선택 사항_ , 기본값은 0.02) — 모든 가중치 행렬을 초기화하기 위한 truncated_normal_initializer의 표준 편차입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.init_xavier_std)**init_xavier_std** ( `float`, _선택 사항_ , 기본값은 1.0) — HM Attention 맵 모듈의 Xavier 초기화 이득에 사용되는 스케일링 요소입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.use_auxiliary_loss)**use_auxiliary_loss** ( `boolean``, *optional*, defaults to` True `) -- If` True Mask2FormerForUniversalSegmentationOutput`에는 각 디코더 단계의 로짓을 사용하여 계산된 보조 손실이 포함됩니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.feature_strides)**feature_strides** ( `List[int]`, _선택 사항_ , 기본값 `[4, 8, 16, 32]`) — 백본 네트워크에서 생성된 기능에 해당하는 기능 스트라이드입니다.
- [](https://huggingface.co/docs/transformers/model_doc/mask2former#transformers.Mask2FormerConfig.output_auxiliary_logits)**output_auxiliary_logits** ( `bool`, _선택 사항_ ) — 모델이 이를 출력해야 하는지 `auxiliary_logits`여부입니다.

[Mask2FormerModel](https://huggingface.co/docs/transformers/v4.46.3/en/model_doc/mask2former#transformers.Mask2FormerModel) 의 구성을 저장하는 구성 클래스입니다 . 지정된 인수에 따라 Mask2Former 모델을 인스턴스화하고 모델 아키텍처를 정의하는 데 사용됩니다. 기본값으로 구성을 인스턴스화하면 Mask2Former [facebook/mask2former-swin-small-coco-instance](https://huggingface.co/facebook/mask2former-swin-small-coco-instance) 아키텍처와 유사한 구성이 생성됩니다.

구성 객체는 [PretrainedConfig](https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/configuration#transformers.PretrainedConfig) 에서 상속되며 모델 출력을 제어하는 ​​데 사용할 수 있습니다. 자세한 내용은 [PretrainedConfig 의 설명서를 읽어보세요.](https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/configuration#transformers.PretrainedConfig)

현재 Mask2Former는 [Swin Transformer](https://huggingface.co/docs/transformers/model_doc/swin) 만을 백본으로 지원합니다.


![](https://i.imgur.com/xIPWypv.png)


```bash
root@instance-13781:~/bohyun/ultralytics# python data_utils.py 
Starting convert data to coco format
800it [00:05, 139.29it/s]
Finish convert data to coco format
Starting convert yolo to coco format
800it [00:10, 73.06it/s]
Finish convert yolo to coco format
Train images:  640
Train labels:  640
Valid images:  160
Valid labels:  160
```
![](https://i.imgur.com/KZxffkJ.png)
엄청난 속도..
```bash
50 epochs completed in 0.627 hours.
Optimizer stripped from Segmentation/T6030_yolo_seg_6409/weights/last.pt, 144.0MB
Optimizer stripped from Segmentation/T6030_yolo_seg_6409/weights/best.pt, 144.0MB

Validating Segmentation/T6030_yolo_seg_6409/weights/best.pt...
Ultralytics 8.3.33 🚀 Python-3.10.13 torch-2.1.0 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)
YOLOv8x-seg summary (fused): 295 layers, 71,748,583 parameters, 0 gradients, 343.8 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4
                   all        160       4640      0.998          1      0.995      0.944      0.994      0.995      0.989      0.844
              finger-1        160        160      0.998          1      0.995      0.979      0.998          1      0.995      0.831
              finger-2        160        160      0.998          1      0.995      0.993      0.998          1      0.995       0.93
              finger-3        160        160      0.998          1      0.995      0.993      0.998          1      0.995      0.959
              finger-4        160        160      0.998          1      0.995      0.967      0.998          1      0.995      0.812
              finger-5        160        160      0.998          1      0.995      0.978      0.998          1      0.995      0.871
              finger-6        160        160      0.998          1      0.995      0.995      0.998          1      0.995      0.964
              finger-7        160        160      0.998          1      0.995      0.992      0.998          1      0.995      0.943
              finger-8        160        160      0.998          1      0.995      0.975      0.998          1      0.995      0.822
              finger-9        160        160      0.998          1      0.995      0.978      0.998          1      0.995      0.913
             finger-10        160        160      0.998          1      0.995      0.995      0.998          1      0.995      0.957
             finger-11        160        160      0.998          1      0.995      0.966      0.998          1      0.995      0.959
             finger-12        160        160      0.998          1      0.995      0.978      0.998          1      0.995      0.827
             finger-13        160        160      0.998          1      0.995      0.991      0.998          1      0.995      0.915
             finger-14        160        160      0.998          1      0.995      0.995      0.998          1      0.995      0.951
             finger-15        160        160      0.998          1      0.995      0.985      0.998          1      0.995      0.897
             finger-16        160        160      0.998          1      0.995      0.978      0.998          1      0.995      0.809
             finger-17        160        160      0.998          1      0.995      0.983      0.998          1      0.995      0.857
             finger-18        160        160      0.998          1      0.995      0.994      0.998          1      0.995      0.945
             finger-19        160        160      0.998          1      0.995      0.989      0.998          1      0.995      0.909
             Trapezium        160        160      0.998          1      0.995      0.809      0.998          1      0.995      0.716
             Trapezoid        160        160      0.999          1      0.995      0.718      0.999          1      0.995      0.659
              Capitate        160        160      0.998          1      0.995      0.888      0.998          1      0.995      0.768
                Hamate        160        160      0.998          1      0.995      0.895      0.998          1      0.995       0.75
              Scaphoid        160        160      0.998          1      0.995      0.962      0.998          1      0.995      0.807
                Lunate        160        160      0.999          1      0.995      0.877      0.999          1      0.995      0.826
            Triquetrum        160        160      0.998          1      0.995      0.892      0.879      0.881      0.829      0.334
              Pisiform        160        160      0.987      0.988      0.987      0.632      0.981      0.981      0.983       0.58
                Radius        160        160      0.998          1      0.995      0.995      0.998          1      0.995      0.995
                  Ulna        160        160      0.998          1      0.995      0.993      0.998          1      0.995      0.972
Speed: 0.4ms preprocess, 12.6ms inference, 0.0ms loss, 1.3ms postprocess per image
Results saved to Segmentation/T6030_yolo_seg_6409
```
# 멘토링
![](https://i.imgur.com/zfSOPwe.png)

외국에서 어린아이 배우 문제가 이슈가 있어서

이미지 하나당 29줄 쭉쭉 나와야되는데 이건 클래스 이름도 안적혀있어
