---
{"dg-publish":true,"permalink":"/4-projects/semantic-seg/24-11-12/"}
---

- [x] 아침운동 1시간 ✅ 2024-11-12
- [ ] 과제 기본1
- [ ] 과제 기본2
- [ ] 과제 기본3
- [x] 🔺 강의다듣기 ✅ 2024-11-13
- [x] 6,7강 퀴즈풀기 ✅ 2024-11-12
- [x] 7강듣기 ✅ 2024-11-12
- [x] 8강듣기 ✅ 2024-11-12
- [x] 8강 퀴즈풀기 ✅ 2024-11-12
- [x] 알고리즘스터디 2시 ✅ 2024-11-12
- [x] 멘토링3시 ✅ 2024-11-12
- [x] 9강듣기 ✅ 2024-11-12
- [x] 10강듣기 ✅ 2024-11-13

7~8강에서 대회에 사용하는 모델과 테크닉들을 위주로 강의
**7강 Semantic Segmentation 대회에서 사용하는 방법들 1**
    - EfficientUnet baseline
    - baseline 이후에 실험 해봐야할 사항들  

#### Augmentation
Cutout
![](https://i.imgur.com/RPC0gJw.png)
![](https://i.imgur.com/w14iFYm.png)
우리가 원하는건 fig1이지만 fig2처럼 객체를 너무 일부만 가리거나 fig3처럼 객체를 아예 다 가려버릴수도 있다.

이 문제점을 해결하기 위해 Gridmask라는 기법이 존재한다.
![](https://i.imgur.com/b1b2OIQ.png)
Albumentations 내 클래스 명이 GridDropout이다.
![](https://i.imgur.com/fSKb8pk.png)
![](https://i.imgur.com/43GMInA.png)
![](https://i.imgur.com/tuTxrzp.png)

Mixup
![](https://i.imgur.com/NgiYIgV.png)
이미지를 x1,x2라고 하자
![](https://i.imgur.com/DESozM6.png)
람다 만큼의 비율로 x1과 x2를 섞어주게 된다.
![](https://i.imgur.com/Li8AItP.png)
out과 label간의 차이를 비교해서 loss를 계산하는게 mixup의 핵심이다.

**Cutmix**
![](https://i.imgur.com/0GBc09o.png)
![](https://i.imgur.com/lLjlx1O.png)
일부 영역은 x2에서 가져오고 일부 영역은 x1에서 가져온다.
![](https://i.imgur.com/Z0ZjuKN.png)
코드를 보면 먼저 얼마만큼 크기의 박스로 자를지 결정을 해준다.
w * cut_ratio, 등등
얼마만큼의 크기로 자를지 결정해주면, 이제 크기를 결정을 해주어야 한다.
![](https://i.imgur.com/JVK9Wr7.png)
그 부분을 담당하는게 cx와 cy다.
cy와 cy를 중심으로 위치를 결정하고 해당 영역을 중심으로 아까 결정했던 w와 h를
![](https://i.imgur.com/FzOSTFZ.png)
np.clip같은 함수는 잘리는 박스가 이미지 밖으로 넘어가지 않도록 해준다.
![](https://i.imgur.com/BKAPHgg.png)
![](https://i.imgur.com/0FkfsTJ.png)
원본이미지에 랜덤index를 가져와서 아래와 같은 결과가 된다.
![](https://i.imgur.com/iguabS9.png)
이제 loss 계산을 해주어야 하는데,
1-람다와 바뀐 타겟 b인 종이상자와 곱해준다.
![](https://i.imgur.com/WBwF04H.png)

SnapMix
![](https://i.imgur.com/42ofNky.png)
CAM을 이용해 이미지의 중요한 영역을 잘라서 그 부분을 교체하는 기법

CropNonEmptyMaskIfExists
![](https://i.imgur.com/ufCWhfO.png)
중요한 부분을 학습한다.

#### Scheduler
![](https://i.imgur.com/D8bFCB4.png)
scheduler를 통해 빠른 속도로 수렴 가능하고 높은 정확도를 가진다.

CosineAnnealingLR: saddle point 정체구간을 빠르게 벗어나게하는 장점이 있다.
![](https://i.imgur.com/C0I4wMl.png)

ReduceLROnPlateau
![](https://i.imgur.com/5GSFZNm.png)
IoU와 loss등으로 확인할 수 있다.

Gradual Warmup: 마스터님이 가장 많이 사용하신다고 한다.
기존 가중치(pretrained)에 대해 불안정한 초반에도 비교적 안정적인 학습을 해서 training process가 안정될 때 까지 기다린다.
![](https://i.imgur.com/PLK1OpG.png)

#### Optimizer / Loss
![](https://i.imgur.com/Ua2b52C.png)

Lookahead optimizer
![](https://i.imgur.com/ZVao2Md.png)
global optimal point에 다가가게 해준다.
![](https://i.imgur.com/1cecXSo.png)
하이브리드 형태의 Loss도 이용가능하다.
꼭 참고해서 사용해보자!

**8강 Semantic Segmentation 대회에서 사용하는 방법들 2**
    - baseline 이후에 실험 해봐야할 사항들 II
    - 대회에서 사용하는 기법들 소개
    - Monitoring Tool

#### Ensemble
SWA 스와 (Stochastic Weight Averaging)
![](https://i.imgur.com/puaaFak.png)
설정한 epoch 이후부터 SWA start
![](https://i.imgur.com/RFtD8qN.png)

![](https://i.imgur.com/qOHNCaz.png)
큰객체,작은객체,중간객체 잘 찾는 모델들간의 시너지를 알아볼 수 있는 앙상블!

TTA
![](https://i.imgur.com/2DmyRgO.png)
inference할 때 입력이미지만 augmentation 해준다.
장점은 k-fold등 모델 여러번 학습해야했던 애들이랑 다르게 train모델은 그대로 쓰고 test시에 inference시간만 조금 늘어나서 좋다.
주의해야할 점은 1. 어떤 augmentation사용해야할지(학습에 사용했던거 사용하면 좋겠죠?) 2. 몇번이나 augmentation 진행할지 3. 가중치
![](https://i.imgur.com/tydNQ3U.png)
![](https://i.imgur.com/0iP0wew.png)
TTA Library인 ttach를 활용할 수 있다.
![](https://i.imgur.com/1v7b0i7.png)
2x2x3 = 12가지 TTA가 가능하다..
![](https://i.imgur.com/MgCdra5.png)
단순 앙상블 하는게 아니라 모델 Inference결과를 본다든지.. 해야함

각자 레이블이라는 의미
보통 test data에 대해 수도 레이블을 만듦
train을 t/v로 나누는데
![](https://i.imgur.com/0Evdprn.png)
1,4번은 큰 확신을 가지고 예측을 했고 2,3번은 비교적 덜 확신했다.
![](https://i.imgur.com/zpmDG4r.png)
#### 외부 데이터 활용
#### Classification 결과 활용
![](https://i.imgur.com/wocbzah.png)
#### 최근 딥러닝 이미지 대회 Trend
![](https://i.imgur.com/J0Rgtgm.png)
데이터 크기가 커지고 양이 많아졌다.
문제점1. 학습하는데 시간이 오래 걸려서 충분한 실험을 하지 못한다.
![](https://i.imgur.com/cRSqMdg.png)

#### Solution 1-1 Mixed-Precision Training
scaler로 AMP활용시 발생할 수 있는 underflow 문제 방지
![](https://i.imgur.com/B75ESZe.png)
![](https://i.imgur.com/SLqFsyl.png)
![](https://i.imgur.com/Nrlishn.png)
FP16 외에도 실험을 간소화 시킬 수 있다.
#### 가벼운 상황으로 실험
![](https://i.imgur.com/HJrLXbU.png)
실험은 hold-out으로하고 제출은 K-fold로 하는 기법 사용!
단, 이때 신뢰성이 낮아지는걸 줄이기 위해서 
![](https://i.imgur.com/p2E4veZ.png)
리더보드와 validation score간의 어느 정도 상관관계가 있는지 실험 하는게 k-fold말고도 의미가 있다는걸 증명해야함
![](https://i.imgur.com/Ef5bx62.png)
여기서 볼 수 있는 점은 실험은 간소하게 진행해서 의미있는 결과를 내고,
최종에 가서 다 적용한 모습을 볼 수 있다.
![](https://i.imgur.com/MB1iV8W.png)

정보량을 풍부하게 만드는 기법
![](https://i.imgur.com/XeGEIlb.png)
가벼운 모델로 실험할 필요성도 있다.
#### Resize
![](https://i.imgur.com/5hNpWmo.png)
1024 1024fmf 256 256으로 학습과 inference한다음에 보간을 해서 1024 1024로 복원하기
근데 주의해야할점은
![](https://i.imgur.com/i1eYsIb.png)
허브맵의 경우 초록색의 벽면을 예측하는 부분이 35000x25000이였는데 resolution이 감소해서 학습과 예측이 잘 안되는 경우도 발생했다.
이러한 문제를 해결하기 위해 생각해볼 수 있는게
![](https://i.imgur.com/a8h12ls.png)
stride size보다 큰 경우는 중복되는 영역이 발생한다. 계속해서 중복하는 영역이 발생한다.

![](https://i.imgur.com/yBO35b7.png)
window사이즈가 같은 경우에는 겹치지 않는다.

두 경우에 어떤 장단점이 있을까?
![](https://i.imgur.com/WiSWILv.png)
![](https://i.imgur.com/tyB5dL4.png)
이렇게 window 사이즈가 작으면 부족하고 한정된 정보를 받을 수 있는데,
![](https://i.imgur.com/S1NFTzw.png)
window사이즈가 크면 풍부한 정보를 받을 수 있는 장점이 있고
![](https://i.imgur.com/vgUtgpR.png)
stride 사이즈를 작게 했을 때 어떤 장점이 있는지 생각해보면
stride 사이즈를 줄였기 때문에 input image 수가 늘어나는 장점이 있다.
![](https://i.imgur.com/nMH3QQR.png)
또 위의 빨간색 두개로 잘랐을땐 왼쪽하나, 오른쪽하나 두가지 case밖에 못봤을텐데
input image 수를 늘림으로써 다양한 상황에 대해서 생각을 해볼 수 있다.
![](https://i.imgur.com/gHnVoQy.png)
![](https://i.imgur.com/Bz5MzMo.png)
필요한 정보를 포함시킬 수 있고 앙상블해서 성능 향상을 얻을 수 있다는 장점이 있다.

반대로 단점도 존재하는데
![](https://i.imgur.com/0a5DoIt.png)
데이터가 늘어났지만 그 늘어난 데이터들 간에 상관성이 높다.

팁이 있는데 반드시 train과 inference의 사이즈를 같게 할 필요는 없다.
![](https://i.imgur.com/qfFqOl5.png)
실제로 inference에서 이미지가 커지면 더 많은 주변 정보를 통해서 성능의 정확도가 올라가는 경우가 경험적으로 많았다.

두번째론 kaggle 허브맵에 나온거처럼 슬라이딩 윈도우를 적용할 때 샘플링을 적용할 수도 있다.
![](https://i.imgur.com/ODD1kKL.png)
의미 없는 배경만 훑다보면 시간도 오래걸리고 불필요한 영역이 많으니까 이런 부분들을 줄여서 학습 속도를 개선할 수 있지 않을까? 생각해서 활용된 기법이
![](https://i.imgur.com/XKwXITQ.png)
박스친 부분에 병변이 있으면 GOOD 없으면 Try Again해서 이 파트는 학습 속도 상승 효과가 있었다.
#### center crop
세번째 팁으로는 sliding window할 때 object의 가장자리만 나오는 경우(의미가 적고 예측하기 어려움
![](https://i.imgur.com/v4tuBqK.png)
object가 제대로 나온 center만 crop해서 이용하는 edge removed 라는 tech
![](https://i.imgur.com/71fwOa8.png)
활용가능성이 높은 tip!!
#### Threshold
주로 threshold를 0.5로 하지만 이게 꼭 정답이 아닐 수 있다.
![](https://i.imgur.com/kKQSOnQ.png)
어떤 카테고리는 0.5, 어떤 카테고리는 0.6 이런식으로 카테고리별로 threshold를 다르게 할 수도 있다.
#### Model 개선 Tip
validation, output의 inference된 이미지를 input image, segmentation과 비교해보면서 어떤 점을 잘하고 있고 어떤 점을 못하고 있는지를 살펴보는게 중요하다!
(validation이 레이블이 있으니까 좀 더 비교하기 편하겠죠?)
![](https://i.imgur.com/Ax6ge3Q.png)
배경부터 클래스까지 잘하고있는 못하고있는 클래스들을 구분해서 
어떤 클래스에 대해서(못하는) 약점을 보완해서 성능을 향상시킬 방법을 고안하자!

#### Label Noise가 있는 경우
![](https://i.imgur.com/UlPCgu7.png)
#### Label smoothing
![](https://i.imgur.com/227ntiV.png)
타겟을 바꿔서 loss를 바꿈

fold가 5라고 했을 때, 
전체 train set에대한 전체 이미지에 대한 실제 label
![](https://i.imgur.com/bcUFxgJ.png)
IoU가 낮은 케이스에 대해서 입력이미지를 일부 버리는 전처리를 할 수도 있고

낮은 IoU에 대해서는 Nosed GT를 활용하는게 아니라 다시 GT를 활용해서 train을 다시 하게되면
![](https://i.imgur.com/uWgILSa.png)
기존의 noise한거 학습한거 대비 성능이 개선될 가능성을 볼 수 있다.
요즘 대회 trend를 보면 accuracy, mIoU등의 다양한 평가 방식을 추가한다.
1. Epcoh앙상블 (다양한 weight 수집)
2. TTA (위에서 수집한 weight를 앙상블)

Monitoring
웹상에 기록하면 비교와 기록에 용이함

 9~10강은 최근 세그멘테이션 연구동향
 9강은 SOTA 모델인 HRNet과 SegFormer - HRNet으로 Cityscape 데이터에서는 좋은 성능을 달성하고 있는 네트워크
- **9강 Semantic Segmentation 연구 동향 1** 
    - 9강   
        - HRNet의 필요성 
        - HRNet 구조 살펴보기 
        - HRNet의 세부 구조 및 구현 
        - HRNet의 실험 결과   

    - 9.1강 
        - 최근 Semantic Segmnetation 연구 동향 
        - SegFormer 구조 살펴보기 
        - SegFormer 세부 구조 및 구현 
        - SegFormer의 실험 결과
# HRNet
![](https://i.imgur.com/tfdyqcr.png)
![](https://i.imgur.com/ABVKurB.png)

# SegFormer
![](https://i.imgur.com/wS0dPEk.png)
![](https://i.imgur.com/mON5Px7.png)
![](https://i.imgur.com/Nab9bTE.png)
![](https://i.imgur.com/90K7lWi.png)


10강은 Weakly Supervised Semantic Segmentation 분야 - 회와는 크게 상관이 없지만 실제 Application 측면에서 강의
- **10강 Semantic Segmentation 연구 동향 2**
    - WSSS 개요
    - CAM 기반의 접근
    - WSSS History
      
