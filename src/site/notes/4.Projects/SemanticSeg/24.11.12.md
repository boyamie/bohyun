---
{"dg-publish":true,"permalink":"/4-projects/semantic-seg/24-11-12/"}
---

- [x] 아침운동 1시간 ✅ 2024-11-12
- [ ] 과제 기본1
- [ ] 과제 기본2
- [ ] 과제 기본3
- [ ] 🔺 강의다듣기
- [x] 7강듣기 ✅ 2024-11-12
- [ ] 8강듣기
- [ ] 9강듣기

7~8강에서 대회에 사용하는 모델과 테크닉들을 위주로 강의
**7강 Semantic Segmentation 대회에서 사용하는 방법들 1**
    - EfficientUnet baseline
    - baseline 이후에 실험 해봐야할 사항들  

#### Augmentation
Cutout
![](https://i.imgur.com/RPC0gJw.png)
![](https://i.imgur.com/w14iFYm.png)
우리가 원하는건 fig1이지만 fig2처럼 객체를 너무 일부만 가리거나 fig3처럼 객체를 아예 다 가려버릴수도 있다.

이 문제점을 해결하기 위해 Gridmask라는 기법이 존재한다.
![](https://i.imgur.com/b1b2OIQ.png)
Albumentations 내 클래스 명이 GridDropout이다.
![](https://i.imgur.com/fSKb8pk.png)
![](https://i.imgur.com/43GMInA.png)
![](https://i.imgur.com/tuTxrzp.png)

Mixup
![](https://i.imgur.com/NgiYIgV.png)
이미지를 x1,x2라고 하자
![](https://i.imgur.com/DESozM6.png)
람다 만큼의 비율로 x1과 x2를 섞어주게 된다.
![](https://i.imgur.com/Li8AItP.png)
out과 label간의 차이를 비교해서 loss를 계산하는게 mixup의 핵심이다.

**Cutmix**
![](https://i.imgur.com/0GBc09o.png)
![](https://i.imgur.com/lLjlx1O.png)
일부 영역은 x2에서 가져오고 일부 영역은 x1에서 가져온다.
![](https://i.imgur.com/Z0ZjuKN.png)
코드를 보면 먼저 얼마만큼 크기의 박스로 자를지 결정을 해준다.
w * cut_ratio, 등등
얼마만큼의 크기로 자를지 결정해주면, 이제 크기를 결정을 해주어야 한다.
![](https://i.imgur.com/JVK9Wr7.png)
그 부분을 담당하는게 cx와 cy다.
cy와 cy를 중심으로 위치를 결정하고 해당 영역을 중심으로 아까 결정했던 w와 h를
![](https://i.imgur.com/FzOSTFZ.png)
np.clip같은 함수는 잘리는 박스가 이미지 밖으로 넘어가지 않도록 해준다.
![](https://i.imgur.com/BKAPHgg.png)
![](https://i.imgur.com/0FkfsTJ.png)
원본이미지에 랜덤index를 가져와서 아래와 같은 결과가 된다.
![](https://i.imgur.com/iguabS9.png)
이제 loss 계산을 해주어야 하는데,
1-람다와 바뀐 타겟 b인 종이상자와 곱해준다.
![](https://i.imgur.com/WBwF04H.png)

SnapMix
![](https://i.imgur.com/42ofNky.png)
CAM을 이용해 이미지의 중요한 영역을 잘라서 그 부분을 교체하는 기법

CropNonEmptyMaskIfExists
![](https://i.imgur.com/ufCWhfO.png)
중요한 부분을 학습한다.

#### Scheduler
![](https://i.imgur.com/D8bFCB4.png)
scheduler를 통해 빠른 속도로 수렴 가능하고 높은 정확도를 가진다.

CosineAnnealingLR: saddle point 정체구간을 빠르게 벗어나게하는 장점이 있다.
![](https://i.imgur.com/C0I4wMl.png)

ReduceLROnPlateau
![](https://i.imgur.com/5GSFZNm.png)
IoU와 loss등으로 확인할 수 있다.

Gradual Warmup: 마스터님이 가장 많이 사용하신다고 한다.
기존 가중치(pretrained)에 대해 불안정한 초반에도 비교적 안정적인 학습을 해서 training process가 안정될 때 까지 기다린다.
![](https://i.imgur.com/PLK1OpG.png)

#### Optimizer / Loss
![](https://i.imgur.com/Ua2b52C.png)

Lookahead optimizer
![](https://i.imgur.com/ZVao2Md.png)
global optimal point에 다가가게 해준다.
![](https://i.imgur.com/1cecXSo.png)
하이브리드 형태의 Loss도 이용가능하다.
꼭 참고해서 사용해보자!

**8강 Semantic Segmentation 대회에서 사용하는 방법들 2**
    - baseline 이후에 실험 해봐야할 사항들 II
    - 대회에서 사용하는 기법들 소개
    - Monitoring Tool

#### Ensemble
SWA 스와 (Stochastic Weight Averaging)
![](https://i.imgur.com/puaaFak.png)
설정한 epoch 이후부터 SWA start
![](https://i.imgur.com/RFtD8qN.png)

![](https://i.imgur.com/qOHNCaz.png)
큰객체,작은객체,중간객체 잘 찾는 모델들간의 시너지를 알아볼 수 있는 앙상블!

TTA
![](https://i.imgur.com/2DmyRgO.png)
inference할 때 입력이미지만 augmentation 해준다.
장점은 k-fold등 모델 여러번 학습해야했던 애들이랑 다르게 train모델은 그대로 쓰고 test시에 inference시간만 조금 늘어나서 좋다.
주의해야할 점은 1. 어떤 augmentation사용해야할지(학습에 사용했던거 사용하면 좋겠죠?) 2. 몇번이나 augmentation 진행할지 3. 가중치
![](https://i.imgur.com/tydNQ3U.png)
![](https://i.imgur.com/0iP0wew.png)
TTA Library인 ttach를 활용할 수 있다.
![](https://i.imgur.com/1v7b0i7.png)
2x2x3 = 12가지 TTA가 가능하다..
![](https://i.imgur.com/MgCdra5.png)
단순 앙상블 하는게 아니라 모델 Inference결과를 본다든지.. 해야함

각자 레이블이라는 의미
보통 test data에 대해 수도 레이블을 만듦
train을 t/v로 나누는데
![](https://i.imgur.com/0Evdprn.png)
1,4번은 큰 확신을 가지고 예측을 했고 2,3번은 비교적 덜 확신했다.
![](https://i.imgur.com/zpmDG4r.png)
#### 외부 데이터 활용
#### Classification 결과 활용
![](https://i.imgur.com/wocbzah.png)
#### 최근 딥러닝 이미지 대회 Trend
![](https://i.imgur.com/J0Rgtgm.png)
데이터 크기가 커지고 양이 많아졌다.
문제점1. 학습하는데 시간이 오래 걸려서 충분한 실험을 하지 못한다.
![](https://i.imgur.com/cRSqMdg.png)

#### Solution 1-1 Mixed-Precision Training
scaler로 AMP활용시 발생할 수 있는 underflow 문제 방지
![](https://i.imgur.com/B75ESZe.png)
![](https://i.imgur.com/SLqFsyl.png)
![](https://i.imgur.com/Nrlishn.png)
FP16 외에도 실험을 간소화 시킬 수 있다.

#### 가벼운 상황으로 실험
![](https://i.imgur.com/HJrLXbU.png)
실험은 hold-out으로하고 제출은 K-fold로 하는 기법 사용!
단, 이때 신뢰성이 낮아지는걸 줄이기 위해서 
![](https://i.imgur.com/p2E4veZ.png)
리더보드와 validation score간의 어느 정도 상관관계가 있는지 실험 하는게 k-fold말고도 의미가 있다는걸 증명해야함
![](https://i.imgur.com/Ef5bx62.png)
여기서 볼 수 있는 점은 실험은 간소하게 진행해서 의미있는 결과를 내고,
최종에 가서 다 적용한 모습을 볼 수 있다.
![](https://i.imgur.com/MB1iV8W.png)

정보량을 풍부하게 만드는 기법
![](https://i.imgur.com/XeGEIlb.png)

가벼운 모델로 실험할 필요성도 있다.

#### Resize
![](https://i.imgur.com/5hNpWmo.png)
1024 1024fmf 256 256으로 학습과 inference한다음에 보간을 해서 1024 1024로 복원하기
근데 주의해야할점은
![](https://i.imgur.com/i1eYsIb.png)
허브맵의 경우 초록색의 벽면을 예측하는 부분이 35000x25000이였는데 resolution이 감소해서 학습과 예측이 잘 안되는 경우도 발생했다.
이러한 문제를 해결하기 위해 생각해볼 수 있는게
![](https://i.imgur.com/a8h12ls.png)
stride size보다 큰 경우는 중복되는 영역이 발생한다. 계속해서 중복하는 영역이 발생한다.

![](https://i.imgur.com/yBO35b7.png)
window사이즈가 같은 경우에는 겹치지 않는다.

두 경우에 어떤 장단점이 있을까?
![](https://i.imgur.com/WiSWILv.png)
![](https://i.imgur.com/tyB5dL4.png)
이렇게 window 사이즈가 작으면 부족하고 한정된 정보를 받을 수 있는데,
![](https://i.imgur.com/S1NFTzw.png)
window사이즈가 크면 풍부한 정보를 받을 수 있는 장점이 있고
![](https://i.imgur.com/vgUtgpR.png)
stride 사이즈를 작게 했을 때 어떤 장점이 있는지 생각해보면
stride 사이즈를 줄였기 때문에 input image 수가 늘어나는 장점이 있다.
![](https://i.imgur.com/nMH3QQR.png)
또 위의 빨간색 두개로 잘랐을땐 왼쪽하나, 오른쪽하나 두가지 case밖에 못봤을텐데
input image 수를 늘림으로써 다양한 상황에 대해서 생각을 해볼 수 있다.
![](https://i.imgur.com/gHnVoQy.png)




 9~10강은 최근 세그멘테이션 연구동향
 9강은 SOTA 모델인 HRNet과 SegFormer - HRNet으로 Cityscape 데이터에서는 좋은 성능을 달성하고 있는 네트워크
- **9강 Semantic Segmentation 연구 동향 1** 
    - 9강   
        - HRNet의 필요성 
        - HRNet 구조 살펴보기 
        - HRNet의 세부 구조 및 구현 
        - HRNet의 실험 결과   
             
    - 9.1강 
        - 최근 Semantic Segmnetation 연구 동향 
        - SegFormer 구조 살펴보기 
        - SegFormer 세부 구조 및 구현 
        - SegFormer의 실험 결과

   
10강은 Weakly Supervised Semantic Segmentation 분야 - 회와는 크게 상관이 없지만 실제 Application 측면에서 강의
- **10강 Semantic Segmentation 연구 동향 2**
    - WSSS 개요
    - CAM 기반의 접근
    - WSSS History