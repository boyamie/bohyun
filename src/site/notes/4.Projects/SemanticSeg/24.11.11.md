---
{"dg-publish":true,"permalink":"/4-projects/semantic-seg/24-11-11/"}
---

### 데일리스크럼 회의록
코드는 각자 따로따로 만들고
프로젝트 처음 시작할 때는(수요일까지) 다 강의를 듣고 피어세션때만 강의를 듣고 
OCR같은 경우 강의 다듣기전까진 잘 모르고
수요일부터 웬만하면 강의 다 들었으니까 Notion 아이디어 스케치하면서 같이

### 강의듣기
#### Overview
이미지 안에 객체가 존재한다고 했을 때, 해당 객체의 위치 식별부터 클래스를 분류하는 방법에 대해 학습한다.
전처리부터 모델 설계, 학습, 추론의 전체적인 딥러닝 파이프라인 및 경진대회에서 사용하는 방법들을 경험한다.
- FCN 
    - 가장 근본이 되는 Segmentation Network 
- DeconvNet / SegNet
    - FCN의 Decoder를 개선 
- DeepLab 
    - FCN의 Receptive Field를 확장
- UNet
    - Contracting과 Expanding을 함께하는 Network  
- HRNet 
    - 고해상도 정보를 계속 유지하는 Network
#### Competition Overview
![](https://i.imgur.com/SqupAoR.png)
- **Input :** hand bone x-ray 객체가 담긴 이미지가 모델의 인풋으로 사용됩니다. segmentation annotation은 json file로 제공됩니다.
- **Output :** 모델은 각 픽셀 좌표에 따른 class를 출력하고, 이를 rle로 변환하여 리턴합니다. 이를 output 양식에 맞게 csv 파일을 만들어 제출합니다.

- 전체 이미지 개수: 800장(Train), 288장(Test)
- 크게 손가락 / 손등 / 팔로 구성되며, 총 29개의 class (뼈 종류)가 존재
'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5', 'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',
'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15', 'finger-16', 'finger-17', 'finger-18', 'finger-19',
'Trapezium', 'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate', 'Triquetrum', 'Pisiform', 'Radius', 'Ulna',  

각각의 train image에 매칭되는 annotation은 json 파일로 제공되고 있으며, json으로 제공되는 파일에는 다양한 keys가 존재하는데, 그 중 annntations에는 "points", "label"이 있으면 이미지의 어느 영역이 레이블인지 알 수 있습니다.
annotations:
- id : ''
- type : 'poly seg'
- attribute : {}
- points : masking 되어 있는 고유의 좌표 (예시 : [[532, 844], [532, 832], ... [418, 747\|532, 844], [532, 832], ... [418, 747]])  
- label : 객체가 해당하는 class name (예시 : 'finger-1')
- 이미지 크기 : (2048 x 2048), 3 channel

9강을 참고해서 [Semantic Segmentation의 SOTA 모델](https://paperswithcode.com/task/semantic-segmentation)들을 직접 구현해보거나 7, 9강을 참고해서 [segmentation_models.pytorch의 패키지](https://github.com/qubvel/segmentation_models.pytorch)를 이용해서 바로 대회에 참여

#### **1강 Introduction**
    - 세그멘테이션 개요
    
**2강 Competition Overview (EDA & Metric)  
- Hand Bone Image Dataset
	multi-label segmentation이다.  ![](https://i.imgur.com/rKUTmyO.png)
	2048 2048 png파일이다.
	![](https://i.imgur.com/tNSURj2.png) 해당 polygon을 구성하는 point좌표만 제공함으로써 메모리 효율성을 가지는 annotation을 만들 수 있다.
- EDA
  크게 손가락 손등 팔로 구성된다. f-19는 19개의 뼈의 종류가 존재한다는 것이다.![](https://i.imgur.com/Ixaa9KD.png)
  클래스 같은 경우 손가락 뼈는 엄지 손가락 마디부터 순서로 부여했고
  다른 뼈들은 이름이 복잡해서 나중에 보도록 한다
  팔뼈 파트는 굉장히 큰 pixel 면적을 차지한다.
  ![](https://i.imgur.com/Kn51SWG.png)
  ![](https://i.imgur.com/EzFTtD9.png)
	실제 클래스의 밀도를 보면 팔 뼈 두가지는 굉장히 높은 분산을 가지고 핑거는 분산이 낮다.
	사람의 손에 대해 팔뼈 아랫부분이 잘리거나 안잘리거나..

	실제 이미지에서 finger도 겹치는 부분이 있다는 점을 유의할 것!
	![](https://i.imgur.com/X3cQHf2.png)
	한 pixel에 여러가지 class가 등장할 수 있다.
	몇몇 클래스들이 많이 겹치는 모습을 볼 수 있다.(진할수록)
	손등 파트의 뼈가 겹치는 경우가 많다.
	![](https://i.imgur.com/ADWB94K.png)
	mask만 활용하는 것이 아니라 gender나 다른 특징을 활용하는 방안을 생각할 수 있다.
- 평가 Metric
  의료 계열에서 많이 사용하는 metric이다.
  dice의 식에서 a는 gt, b는 pred이다.
  ![](https://i.imgur.com/GujpYL1.png)
  위 식에서는 red class에 대한 dice를 계산해서 0.5가 되는 계산식이다.
  ![](https://i.imgur.com/Z3jogLG.png)
  그린도 마찬가지로 gt와 pred의 교집합인 3칸 x2 가 분자이고 분모는 두 개 각각의 칸수를 더한다
  ![](https://i.imgur.com/VUGe6kD.png)
  코드와 함께 살펴보면 입력 이미지가 (배치,채널,height,width)로 들어오면 
  먼저 t_true와 y_pred에 대해 spatial 차원에 대해 flatten을 진행한다.
  그 이후 교집합은 torch.sum함수를 이용해서 계산한다.
  분모 파트는 각각에 대해서 크기를 계산한다.
  
  이 파트를 그림으로 살펴보면![](https://i.imgur.com/Ecemrji.png)
  다이스를 각각의 클래스에 대해 계산을 하는데 이건 C와 연관이 있다.
  flatten을 시켜주면 spatial의 차원이 y_pred_f, y_ture_f가 된다.
  그 이후에 분모 파트를 먼저 보면 -1에 대해서 torch.sum을 수행하게 되는데 이 의미는 0,1로 구성되어 있는 값에서 1의 개수가 총 몇개인지 합을 구하겠다는 의미이다.
  
  분자
  ![](https://i.imgur.com/YHvaGWa.png)
  교집합의 연산은 위의 코드다. 0과 1을 곱하는 과정에서 0이 하나라도 있으면 0이 된다.
  즉 같은 픽셀에 대해 둘다 1인 경우에만 1이 되어 intersection이 되고 그걸 torch.sum으로 더해줘서 최종 분자가 된다.
- Baseline Code

   

- **3강 Semantic Segmentation의 기초와 이해**
 FCN 논문을 기반으로 Segmentation 태스크가 무엇인지에 대한 이해
    - 대표적인 딥러닝을 이용한 세그멘테이션 FCN
    - 결론
    - **기본과제-1 : FCN8, FCN16, FCN32**제출 기한 : 실습은 따로 제출하지 않습니다.  
        

  
4~6강에서 기존의 모델은 **어떠한 한계점**이 있고 이러한 한계점을 어떻게 극복했는지의 위주로 강의
- **4강 FCN의 한계를 극복한 모델들 1**
    - FCN의 한계점
    - Decoder를 개선한 models
    - Skip Connection을 적용한 models
    - Receptive Field를 확장시킨 models
    - **기본과제-2 : DeconvNet, DilatedNet, SegNet, DeepLabV1  
        **제출 기한 : 실습은 따로 제출하지 않습니다.

   

- **5강 FCN의 한계를 극복한 모델들 2**
    - Receptive Field를 확장시킨 models
    - 결론  
        
    - **기본과제-3 : DeepLabV2, DeepLabV3, DeepLabV3+**제출 기한 : 실습은 따로 제출하지 않습니다.

  

- **6강 High Performance를 자랑하는 U-Net 계열의 모델들**
    - U-Net
    - U-Net++
    - U-Net 3+
    - Another version of the U-Net
    - 결론
    - **심화과제-1 : Unet / Unet++**제출 기한 : 실습은 따로 제출하지 않습니다.  
          
        

7~8강에서 대회에 사용하는 모델과 테크닉들을 위주로 강의
- **7강 Semantic Segmentation 대회에서 사용하는 방법들 1**
    - EfficientUnet baseline
    - baseline 이후에 실험 해봐야할 사항들  
        

   

- **8강 Semantic Segmentation 대회에서 사용하는 방법들 2**
    - baseline 이후에 실험 해봐야할 사항들 II
    - 대회에서 사용하는 기법들 소개
    - Monitoring Tool

 9~10강은 최근 세그멘테이션 연구동향
 9강은 SOTA 모델인 HRNet과 SegFormer - HRNet으로 Cityscape 데이터에서는 좋은 성능을 달성하고 있는 네트워크
- **9강 Semantic Segmentation 연구 동향 1** 
    - 9강   
        - HRNet의 필요성 
        - HRNet 구조 살펴보기 
        - HRNet의 세부 구조 및 구현 
        - HRNet의 실험 결과   
             
    - 9.1강 
        - 최근 Semantic Segmnetation 연구 동향 
        - SegFormer 구조 살펴보기 
        - SegFormer 세부 구조 및 구현 
        - SegFormer의 실험 결과

   
10강은 Weakly Supervised Semantic Segmentation 분야 - 회와는 크게 상관이 없지만 실제 Application 측면에서 강의
- **10강 Semantic Segmentation 연구 동향 2**
    - WSSS 개요
    - CAM 기반의 접근
    - WSSS History