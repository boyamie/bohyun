---
{"dg-publish":true,"permalink":"/4-projects//"}
---

# 사전질문 1
### **1. 오디오 데이터 경량화**

#### **1.1. 고차계수 연산 생략**

MFCC(Mel-Frequency Cepstral Coefficients)에서 고차 계수는 보통 신호의 세부적인 텍스처를 설명하지만, 일부 작업에서는 고차 계수 생략이 성능에 큰 영향을 미치지 않습니다. 이를 통해 데이터 크기를 줄이고 처리 속도를 높일 수 있습니다.
- MFCC 추출 시 고차 계수를 포함하지 않고, 주요 성분(예: 첫 13차 계수)만 사용.
- 차원 축소로 계산 복잡도 감소 및 모델 처리 최적화.

#### **1.2. 정규화**

오디오 데이터는 모델이 다룰 수 있는 범위로 정규화해야 합니다. 정규화는 데이터 분포를 안정화하고 학습 수렴을 촉진합니다.
- 전체 데이터 세트의 RMS(root mean square)를 기준으로 신호를 정규화.
- dB 단위로 변환하여 상대적 에너지를 표현.
- 클리핑 및 노이즈 제거로 아웃라이어 데이터 제거.

#### **1.3. 세그먼트 분할**

오디오 데이터를 작은 세그먼트로 나누어 훈련 데이터를 더 풍부하게 만들 수 있습니다. 이는 데이터 양을 늘리고 모델 훈련에 필요한 메모리를 줄이는 데 유리합니다.

- 고정 길이로 분할(예: 1~2초 단위).
- Overlapping Windowing 기법으로 데이터 중복성을 활용해 정보 손실 최소화.

---

### **2. 오디오 데이터 증강 기법**

#### **2.1. Noise Injection**

데이터 다양성을 늘리고 모델의 일반화 성능을 높이기 위해 배경 소음을 추가하는 방식입니다.

- Gaussian Noise, Pink Noise 등을 추가.
- 다양한 SNR(Signal-to-Noise Ratio) 조건에서 증강된 데이터를 생성.

#### **2.2. Time Stretching**

오디오 데이터를 일정 비율로 늘리거나 줄여 시간적 변화를 모사합니다.

- STFT(Short-Time Fourier Transform)를 사용해 시간 스케일 변경.
- 과도한 왜곡을 방지하기 위해 ±10% 이내로 조정.

#### **2.3. Pitch Shifting**

음조를 조정하여 다양한 음역대를 모사합니다.

- Mel-spectrogram이나 MFCC 생성 이전에 샘플 속도를 조정.
- 음높이 변화 후 원래 시간 길이로 조정.

#### **2.4. Room Impulse Response (RIR) 적용**

실제 환경에서의 음향 특성을 반영하기 위해 인공적으로 잔향을 추가합니다.

- RIR 데이터셋 사용(예: 다양한 실내 환경을 반영한 IR 데이터).
- 훈련 시 정규화하여 지나친 잔향이 학습에 방해되지 않도록 조정.

#### **2.5. SpecAugment**

Mel-spectrogram에 대해 시간 및 주파수 차원에서 마스킹을 적용하는 기법입니다.

- 주파수 대역 마스킹(Frequency Masking): 특정 주파수 영역을 무작위로 가림.
- 시간 대역 마스킹(Time Masking): 오디오의 특정 시간 간격을 무작위로 가림.
- Time Warping: 시간 축을 약간 왜곡하여 변형.

#### **2.6. Volume Perturbation**

오디오 신호의 볼륨을 임의로 조정하여 다양한 녹음 환경을 반영합니다.

- ±3~5dB 범위로 볼륨을 무작위 변경.
- 원래 신호의 특징이 손상되지 않도록 주의.

#### **2.7. Mixing**

서로 다른 두 오디오 샘플을 혼합하여 새로운 데이터를 생성합니다.

- 샘플 간 가중치를 달리하여 혼합.
- 결과 신호의 에너지를 정규화.

---

### **3. 데이터 전처리에서 AMP 적용 및 MFCC로의 변경**

#### **3.1. AMP (Amplitude Modulation Processing) 적용**

- Amplitude Modulation을 활용하여 오디오의 에너지를 기반으로 신호를 강조하거나 약화합니다.
- **효과**: 중요한 음향 정보가 강조되고, 불필요한 잡음이 감소.

#### **3.2. Mel Spectrogram → MFCC로 변경 검토**

- **Mel-spectrogram의 단점**: 주파수 대역 정보를 효과적으로 보존하지만, 음성 특징 추출 측면에서는 MFCC보다 세밀하지 않을 수 있음.
- **MFCC의 장점**: 음향의 심리음향학적 특성 반영. 음성 관련 작업에 특히 유리.
- **변경 전략**
    - 기존 Mel-spectrogram 파이프라인을 MFCC 추출 파이프라인으로 대체.
    - 테스트 데이터에서 MFCC의 효과를 비교하여 변경 여부 결정.

---

### **4. 경량 모델의 데이터 전처리 및 증강 활용**

Salmonn 모델과 같은 경량 모델은 대규모 데이터셋에서 학습된 Foundation 모델을 기반으로 하기 때문에, 데이터 전처리와 증강 전략은 경량화된 모델에서도 중요한 성능 개선 요소입니다.

- **학습 데이터 경량화**: Stage1 및 Stage2 데이터를 중심으로 핵심 데이터만 사용.
- **증강 기법 활용**: 전처리를 최소화했지만, 추가적인 증강을 통해 경량 모델의 다양성을 보완.

---
# 사전질문 2
### **1. 오디오 데이터 경량화 기법**

#### **1.1. 샘플링 레이트 최적화**

오디오 데이터의 샘플링 레이트를 조정하면 데이터 크기를 줄이고 계산량을 낮출 수 있음. 예를 들어, 일반적인 음성 인식 작업에서는 16kHz 샘플링 레이트가 충분히 좋은 성능을 제공.

- 데이터가 44.1kHz와 같은 고해상도라면 16kHz로 다운샘플링.
- 디지털 필터를 사용해 샘플링 변경 과정에서의 품질 손실 최소화.

#### **1.2. 길이 조정 및 세그먼트화**

오디오 데이터의 길이가 불필요하게 긴 경우 학습 속도를 낮출 수 있음. 데이터 세그먼트화로 처리 속도를 높이고 다양한 샘플을 생성.

- 고정 길이로 자르기(예: 1~2초).
- Overlapping Windowing 기법으로 데이터 중복 활용.
- 긴 오디오에서 의미 없는 구간(무음)을 제거해 데이터 크기를 줄임.

#### **1.3. 압축 및 차원 축소**

MFCC(Mel-Frequency Cepstral Coefficients)를 활용하면 오디오 데이터의 차원을 대폭 줄이면서 주요 특성을 보존 가능.

- MFCC의 저차원 계수(예: 첫 13개)만 사용.
- 고차 계수를 생략해 정보의 과적합 가능성을 줄임.

#### **1.4. 양자화 (Quantization)**

오디오 데이터를 더 낮은 정밀도로 변환해 메모리 사용량을 줄이고 처리 속도를 향상.

- 16비트 오디오 데이터를 8비트 또는 4비트 정밀도로 변환.
- 양자화 후 신호 품질 유지 여부를 실험적으로 검증.

#### **1.5. 노이즈 제거 및 클리핑**

데이터에 포함된 불필요한 노이즈나 클리핑된 신호를 제거하면 처리 효율성을 높일 수 있음.

- Bandpass Filtering으로 주요 주파수 대역만 보존.
- 무음 구간을 제거하고 신호 대 노이즈 비율(SNR)을 최적화.

---

### **2. 오디오 데이터 증강 기법**

#### **2.1. Noise Injection**

배경 소음이나 Gaussian Noise를 추가해 모델의 일반화 성능을 강화.

- 데이터에 Gaussian Noise를 추가해 다양한 환경을 시뮬레이션.
- SNR(Signal-to-Noise Ratio)을 조정하며 실험.

#### **2.2. Pitch Shifting**

오디오의 음조를 변경해 모델이 다양한 음역대를 학습하도록 유도.

- 샘플 속도를 조정해 음높이를 ±1~2 반음 변화.
- 변형 후 원래의 신호 길이를 유지.

#### **2.3. Time Stretching**

시간 스케일을 조정해 신호 길이를 늘리거나 줄임.

- Time Stretching 기법으로 ±10%의 속도 변화 적용.
- STFT(Short-Time Fourier Transform) 기반으로 왜곡 최소화.

#### **2.4. SpecAugment**

Mel-spectrogram에서 특정 영역을 마스킹해 모델의 일반화 성능을 향상.

- Frequency Masking: 특정 주파수 대역을 무작위로 가림.
- Time Masking: 특정 시간 대역을 무작위로 가림.
- Time Warping: 시간 축을 왜곡해 변형.

#### **2.5. Room Impulse Response (RIR) 적용**

실제 환경에서의 잔향 효과를 반영해 현실적인 학습 데이터를 생성.

- RIR 데이터셋을 사용해 잔향을 추가.
- 실내, 야외 등 다양한 환경 조건을 반영.

#### **2.6. Mixing**

서로 다른 오디오 샘플을 혼합해 새로운 데이터 샘플을 생성.

- 두 샘플 간 가중치를 다르게 설정해 혼합.
- 혼합 후 신호의 에너지 정규화.

#### **2.7. Volume Perturbation**

볼륨을 무작위로 조정해 다양한 녹음 환경을 모사.

- ±3~5dB 범위에서 볼륨 조정.
- 신호 특성이 유지되도록 과도한 조정 방지.

---

### **3. 가설 검증과 경량화 실험 환경에의 적용**

#### **3.1. 경량화 전략**

- **고성능 모델 경량화**:
    - **Quantization-aware Training**: 양자화를 염두에 둔 훈련으로 성능 저하 최소화.
    - **Iterative Pruning**: 중요하지 않은 뉴런을 반복적으로 제거하면서 재학습.
- **저성능 모델 성능 개선**:
    - **Pruning + Re-train**: 단순히 모델을 압축하기보다 재학습으로 성능 개선.
    - **Data Augmentation 활용**: 부족한 데이터의 다양성을 증대해 성능 보완.

#### **3.2. 성능 평가 지표**

- **WER (Word Error Rate)**: 음성 인식 정확도를 평가하기 위한 표준 지표.
- **SPIDEr**: 오디오 캡셔닝과 같은 복잡한 멀티모달 task에서 사용되는 지표로, BLEU, CIDEr 등의 종합 지표를 활용.

#### **3.3. 실험 환경 설정**

- 모델 경량화 후 **latency**, **memory usage**, **text generation 결과**를 평가.
- **리더보드 제출 전 사전 검증**:
    - 모델이 불필요하게 긴 텍스트를 생성하지 않도록 디버깅.
    - 반복 생성 방지: Beam Search, Sampling 등 최적화 기법 활용.

# 사전질문 3
### **1. 오디오 데이터 경량화 기법**

#### **1.1. 샘플링 레이트 최적화**

오디오 데이터를 모델에 적합하게 만들기 위해 샘플링 레이트를 조정하여 데이터 크기를 줄이고 처리 속도를 높입니다.

- **적용 방안**:
    - 일반적인 음성 인식 작업에서는 16kHz 샘플링 레이트가 적합.
    - 고해상도 오디오(예: 44.1kHz)는 다운샘플링을 통해 데이터 크기를 줄이고 계산량 감소.
    - 리샘플링 시 품질 유지 필터 적용.

#### **1.2. 신호 길이 조정**

오디오 데이터의 불필요하게 긴 길이는 모델 처리에 부담을 줄 수 있으므로 길이를 조정하거나 세그먼트로 나눕니다.

- **적용 방안**:
    - 일정 길이(예: 1~2초)로 오디오 데이터를 분할.
    - Overlapping Windowing 기법을 사용해 중복 데이터를 생성하여 정보 손실 최소화.
    - 무음 구간 제거로 데이터를 간소화.

#### **1.3. 차원 축소**

오디오 데이터를 모델이 처리하기 쉽게 차원을 줄입니다.

- **적용 방안**:
    - MFCC(Mel-Frequency Cepstral Coefficients)를 사용하여 음성의 주요 특성만 추출.
    - 낮은 차원의 MFCC 계수(예: 첫 13개)만 사용하여 처리 효율성을 높임.

#### **1.4. 압축 및 양자화**

오디오 데이터를 압축하거나 양자화하여 모델 학습에 필요한 메모리와 계산량을 줄입니다.

- **적용 방안**:
    - 오디오 데이터를 16비트에서 8비트 또는 4비트로 양자화.
    - 양자화 후 음질 저하 여부를 검증하여 최적화.

#### **1.5. 노이즈 제거**

데이터에 포함된 불필요한 노이즈나 클리핑 신호를 제거하여 학습 데이터의 품질을 향상.

- **적용 방안**:
    - Bandpass Filtering을 사용해 특정 주파수 대역의 신호만 보존.
    - SNR(Signal-to-Noise Ratio)을 최적화하여 신호 품질을 개선.

---

### **2. 오디오 데이터 증강 기법**

#### **2.1. Noise Injection**

모델이 다양한 환경에서 학습할 수 있도록 백색 소음 또는 배경 소음을 추가합니다.

- **적용 방안**:
    - Gaussian Noise, Pink Noise 등 다양한 유형의 소음을 추가.
    - SNR 값을 조정해 소음 비율을 다양하게 적용.

#### **2.2. Pitch Shifting**

오디오의 음조를 변화시켜 모델이 다양한 음역대를 학습하도록 유도합니다.

- **적용 방안**:
    - 오디오의 음조를 ±1~2 반음 조정.
    - 변형된 신호가 원래 시간 길이를 유지하도록 재조정.

#### **2.3. Time Stretching**

시간 스케일을 조정해 신호의 길이를 늘리거나 줄여 시간적 변화를 학습할 수 있도록 합니다.

- **적용 방안**:
    - STFT(Short-Time Fourier Transform)를 사용해 시간 축을 조정.
    - ±10% 이내로 시간 스케일을 변경해 과도한 왜곡 방지.

#### **2.4. SpecAugment**

Mel-spectrogram에서 특정 영역을 마스킹하여 모델이 다양한 변형에 대해 강건해지도록 합니다.

- **적용 방안**:
    - Frequency Masking: 특정 주파수 대역을 무작위로 마스킹.
    - Time Masking: 특정 시간 영역을 무작위로 마스킹.
    - Time Warping: 시간 축을 왜곡하여 변형된 데이터를 생성.

#### **2.5. Room Impulse Response (RIR)**

잔향을 추가해 실제 환경에서의 오디오 데이터를 시뮬레이션.

- **적용 방안**:
    - 다양한 환경(실내, 야외)의 RIR 데이터를 사용하여 잔향 추가.
    - 다양한 반사 특성을 가진 공간 조건을 반영.

#### **2.6. Mixing**

서로 다른 두 오디오 데이터를 혼합하여 새로운 데이터를 생성.

- **적용 방안**:
    - 두 신호를 가중치 비율을 달리하여 혼합.
    - 혼합 후 신호의 RMS 또는 dB를 정규화.

#### **2.7. Volume Perturbation**

볼륨을 무작위로 조정하여 다양한 녹음 환경을 반영합니다.

- **적용 방안**:
    - ±3~5dB 범위에서 볼륨을 무작위로 변경.
    - 조정된 신호의 특징이 손상되지 않도록 범위를 제한.

#### **2.8. 데이터 증강과 Knowledge Distillation 연계**

증강된 데이터를 활용해 Teacher 모델에서 Student 모델로 지식을 전달.

- **적용 방안**:
    - Teacher 모델이 생성한 증강 데이터를 Student 모델에 학습.
    - Teacher/Student 간 차원을 맞추고 Intermediate Representation Distillation 적용.

---

### **3. 경량화 및 증강 기법의 실험 적용**

#### **3.1. 경량화의 타겟 정의**

- **ASR (Automatic Speech Recognition)**: Word Error Rate(WER)를 낮추기 위해 음성 데이터를 효율적으로 압축.
- **AAC (Audio Captioning)**: SPIDEr 점수를 높이기 위해 다양한 데이터 증강을 적용.

#### **3.2. 모델 구조 고려**

- 경량화 모델이 **Teacher 모델**로부터 지식을 전달받을 때, 적합한 구조와 차원 매칭 필요.
- Pruning, Quantization, Knowledge Distillation 등 경량화 방법과 데이터 증강 기법 병행.

# Reference

